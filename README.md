# information-retrieval

Topic model is a very popular document representing model nowadays. In the topic model, topics are the vocabulary word’s distribution, which is represented as the words’ probabilities in the topic. However, the answer for the question if the topic model can improve IR is still not so clear. So, the objective of this experiment is try to prove that the topic model can improve IR. And here we use the LDA topic model to do the experiment. LDA model is a very popular probabilistic topic model, in which each document has several topics and each topic have different distribution in different documents. LDA model is a probabilistic model with a corresponding generative process, in which θ-the topic distribution in each document and φ-the word distribution in each topic is the most two important parameters to estimate. In this experiment, I use the Gibbs sampling method to estimate θ and φ by MALLET [1]. In this experiment, three baseline models – QL (with Dirichlet smoothing) model, DFR-PL2 and DFR-DL2 are used to compare with LBDM model. Two data collections -Trec123 and Robust04, including the query sets and relevance judgments, were used in the experiment. Each parameter in the four different models was estimated by statistic cross validation machine learning method. The performance of each model were evaluated by the mean of average precision(AP), nDCG@10 and ERR@10 metrics, which is compared to the experiment conducted by Xin and W.Bruce
